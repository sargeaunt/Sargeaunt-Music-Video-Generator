<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Dynamic Music Video Sync</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: #000;
      font-family: Arial, sans-serif;
    }

    /* Background image behind text */
    #background-image {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      background-image: url('https://i.imgur.com/tTqqjda.png');
      background-size: cover;
      background-position: center;
      background-repeat: no-repeat;
      z-index: -1;
    }

    canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
    }

    /* Center the buttons (splash) */
    .upload-buttons {
      position: absolute;
      top: 70%;
      left: 50%;
      transform: translate(-50%, -50%);
      text-align: center;
      z-index: 1;
    }

    /* Hidden file inputs */
    input[type="file"] {
      opacity: 0; width: 200px; height: 50px;
      position: absolute; z-index: -1;
    }

    label {
      display: inline-block;
      background-color: #fff; color: #000;
      padding: 10px 20px; margin: 10px; font-size: 16px;
      border-radius: 10px; cursor: pointer; border: 2px solid #fff;
      transition: all 0.3s ease;
    }
    label:hover { background-color: #f0f0f0; }

    #start-button {
      padding: 10px 20px; background-color: #fff; color: #000;
      border: none; cursor: pointer; opacity: 0.8;
      border-radius: 10px; font-size: 18px; border: 2px solid #fff;
    }
    #start-button:hover { background-color: #f0f0f0; }

    /* --- Recording UI --- */
    #toggle-record {
      display:inline-block;
      background:#111; color:#fff;
      border:2px solid #fff; border-radius:10px;
      padding:10px 20px; margin:10px; font-size:16px;
      cursor:pointer; transition:transform .15s ease, background .15s ease;
    }
    #toggle-record.active { background:#d92323; } /* red when ON */
    #toggle-record:hover { transform: translateY(-1px); }

    #stop-recording {
      position: fixed;
      left: 16px; bottom: 16px;
      z-index: 3; display: none; /* shown only while recording */
      width: 44px; height: 44px; border-radius: 10px;
      background: rgba(0,0,0,0.6);
      border: 2px solid rgba(255,255,255,0.9);
      backdrop-filter: blur(6px);
      align-items: center; justify-content: center;
      cursor: pointer; transition: transform .15s ease;
    }
    #stop-recording:hover { transform: translateY(-2px); }
    #stop-recording svg { width: 22px; height: 22px; fill: #ff4d4d; }
  </style>
</head>
<body>

  <!-- Background Image -->
  <div id="background-image"></div>

  <!-- Splash -->
  <div class="upload-buttons">
    <label for="audio-upload">Choose Audio</label>
    <input type="file" id="audio-upload" accept="audio/*" />

    <button id="start-button" disabled>Start</button>

    <label for="video-upload">Choose Video</label>
    <input type="file" id="video-upload" accept="video/*" />

    <!-- Record toggle -->
    <button id="toggle-record" aria-pressed="false" title="Record video (WebM)">Record video</button>
  </div>

  <canvas id="visualizer"></canvas>

  <!-- Unobtrusive stop button (not recorded; we only record the canvas) -->
  <button id="stop-recording" aria-label="Stop and download recording" title="Stop & download">
    <svg viewBox="0 0 24 24" aria-hidden="true"><rect x="7" y="7" width="10" height="10" rx="2"></rect></svg>
  </button>

  <script>
    const canvas = document.getElementById('visualizer');
    const ctx = canvas.getContext('2d');
    const audioUpload = document.getElementById('audio-upload');
    const videoUpload = document.getElementById('video-upload');
    const startButton = document.getElementById('start-button');
    const uploadButtons = document.querySelector('.upload-buttons');

    // Recording UI
    const recordToggleBtn = document.getElementById('toggle-record');
    const stopRecordBtn = document.getElementById('stop-recording');

    let audioContext, analyser, frequencyData, audioElement;
    let mediaDest; // for recording audio
    let mediaRecorder, recordedChunks = [];
    let isRecording = false;
    let recordEnabled = false;

    let videoElement, lastCutTime = 0;
    let videoPlaying = false;
    let currentFrameDuration = 1; // retained, not used for cut logic now
    let beatIntensity = 0;        // retained for compatibility

    let audioFile, videoFile;

    // ---------- New onset detection state ----------
    // Previous spectrum for spectral flux
    let prevFreq = null;

    // Rolling flux history for adaptive threshold
    const FLUX_HISTORY_FRAMES = 45; // ~0.75s @60fps
    const fluxHistory = new Array(FLUX_HISTORY_FRAMES).fill(0);
    let fluxIndex = 0;
    let fluxCount = 0;

    // Small stack of recent spectra to estimate percussive dominance
    const SPEC_HISTORY = 8;
    const specStack = new Array(SPEC_HISTORY);
    let specPtr = 0;
    let specCount = 0;

    // Onset timestamps for density-based min interval
    const onsetTimes = [];
    const DENSITY_WINDOW = 3.0; // seconds

    // Long-hold protection when music gets sparse
    let lastOnsetAt = 0;
    const LONG_HOLD_TIMEOUT = 2.5; // if no onsets for this long
    const LONG_HOLD_EXTRA = 1.6;   // add this much to min interval

    // Base minimum interval (keeps a bit of unpredictability but prevents micro-cuts)
    const BASE_MIN_INTERVAL = 0.30;

    function resizeCanvas() {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    }

    // Load and play video
    function loadVideo(file) {
      videoElement = document.createElement('video');
      videoElement.src = URL.createObjectURL(file);
      videoElement.loop = true;
      videoElement.muted = true;
      videoElement.play();
      videoElement.style.position = 'absolute';
      videoElement.style.top = '0';
      videoElement.style.left = '0';
      videoElement.style.width = '100%';
      videoElement.style.height = '100%';
      document.body.appendChild(videoElement);
      videoPlaying = true;
    }

    // Jump to a specific section of the video with slight randomness
    function jumpToVideoSection(novelty) {
      // Map novelty to broad quarters, then add small jitter to keep it organic
      const n = Math.max(0, Math.min(255, novelty));
      let baseStart;
      if (n < 70)       baseStart = Math.random() * 0.25;           // 0–25%
      else if (n < 140) baseStart = Math.random() * 0.5 + 0.25;     // 25–75%
      else if (n < 220) baseStart = Math.random() * 0.25 + 0.75;    // 75–100%
      else              baseStart = Math.random();                   // spikes → anywhere

      // tiny temporal jitter (±2% of duration) to avoid feeling grid-locked
      const jitter = (Math.random() - 0.5) * 0.04;

      if (videoElement.duration && isFinite(videoElement.duration)) {
        const t = Math.max(0, Math.min(1, baseStart + jitter));
        videoElement.currentTime = videoElement.duration * t;
      }
    }

    // ---------- Maths helpers ----------
    function median(arr) {
      const a = arr.slice(0).sort((x,y)=>x-y);
      const m = a.length >> 1;
      return (a.length % 2) ? a[m] : 0.5 * (a[m-1] + a[m]);
    }
    function mad(arr, med) {
      const dev = arr.map(v => Math.abs(v - med));
      return median(dev) || 1e-6;
    }

    // Compute spectral flux (positive changes only) in low-mid bands
    function spectralFlux(curr, prev, startBin, endBin) {
      let sum = 0;
      for (let i = startBin; i < endBin; i++) {
        const d = curr[i] - prev[i];
        if (d > 0) sum += d;
      }
      return sum / (endBin - startBin);
    }

    // Cheap percussive dominance score: compare current spectrum to time-median
    function percussiveScore(curr) {
      if (specCount < SPEC_HISTORY) return 0.5; // neutral until we have history

      // Build per-bin median from history
      const bins = curr.length;
      const med = new Array(bins);
      for (let i = 0; i < bins; i++) {
        const col = [];
        for (let j = 0; j < SPEC_HISTORY; j++) col.push(specStack[j][i]);
        med[i] = median(col);
      }
      // Count bins exceeding median by a small margin → percussive pops
      let hits = 0, considered = 0;
      for (let i = 2; i < Math.min(64, bins); i++) { // focus lows/mids
        if (curr[i] > med[i] + 6) { hits++; }
        considered++;
      }
      return considered ? hits / considered : 0.5;
    }

    // Push current spectrum into specStack
    function pushSpectrumCopy(arr) {
      const copy = new Uint8Array(arr.length);
      copy.set(arr);
      specStack[specPtr] = copy;
      specPtr = (specPtr + 1) % SPEC_HISTORY;
      if (specCount < SPEC_HISTORY) specCount++;
    }

    // Update flux history ring buffer
    function pushFlux(f) {
      fluxHistory[fluxIndex] = f;
      fluxIndex = (fluxIndex + 1) % FLUX_HISTORY_FRAMES;
      if (fluxCount < FLUX_HISTORY_FRAMES) fluxCount++;
    }
    function getFluxStats() {
      const arr = fluxHistory.slice(0, fluxCount);
      const med = median(arr);
      const m = mad(arr, med);
      return { med, m };
    }

    // Keep recent onsets
    function noteOnset(time) {
      onsetTimes.push(time);
      lastOnsetAt = time;
      // drop old
      while (onsetTimes.length && (time - onsetTimes[0]) > DENSITY_WINDOW) {
        onsetTimes.shift();
      }
    }
    function onsetDensity(now) {
      // count within window
      while (onsetTimes.length && (now - onsetTimes[0]) > DENSITY_WINDOW) {
        onsetTimes.shift();
      }
      return onsetTimes.length / DENSITY_WINDOW; // per second
    }

    // Decide whether to cut this frame
    function shouldCut(now, novelty, percScore) {
      // Dynamic min interval based on onset density
      const density = onsetDensity(now); // onsets per second in last 3s
      // Map density to multiplier: sparse → bigger interval
      // 0/s → x4, 0.3/s → x3, 1.0/s → x2, 1.7+/s → x1
      let mult = 4.0;
      if (density >= 1.7) mult = 1.0;
      else if (density >= 1.0) mult = 2.0;
      else if (density >= 0.3) mult = 3.0;

      // Additional hold when music is very sparse
      let extraHold = 0;
      if (now - lastOnsetAt > LONG_HOLD_TIMEOUT) extraHold = LONG_HOLD_EXTRA;

      const effectiveMin = BASE_MIN_INTERVAL * mult + extraHold;
      const since = now - lastCutTime;

      // Adaptive threshold using flux history
      const { med, m } = getFluxStats();
      const thresh = med + 2.5 * m; // robust, adapts to song sections

      // Scale novelty by percussive dominance: vocals → smaller score
      const score = novelty * (0.6 + 0.8 * percScore); // in [~0.6x .. ~1.4x]

      // Gate: need to exceed threshold and respect min interval
      if (since >= effectiveMin && score > thresh) {
        return true;
      }
      return false;
    }

    // Flash + cut logic using spectral flux instead of raw energy
    function cutLogic() {
      if (!audioContext || !analyser || !frequencyData) return;

      // Get current spectrum
      analyser.getByteFrequencyData(frequencyData);

      const bins = frequencyData.length;
      const startBin = 2;
      const endBin   = Math.min(64, bins); // low–mid focus

      // Compute novelty (spectral flux) if we have a previous frame
      let novelty = 0;
      if (prevFreq) {
        novelty = spectralFlux(frequencyData, prevFreq, startBin, endBin);
      }

      // Push to histories (for next decisions)
      pushFlux(novelty);
      pushSpectrumCopy(frequencyData);

      // Percussive dominance estimate (down-weights vocal-only parts)
      const pScore = percussiveScore(frequencyData);

      const now = audioContext.currentTime;

      // Decide to cut?
      if (prevFreq && shouldCut(now, novelty, pScore)) {
        lastCutTime = now;
        noteOnset(now);
        // Jump to a section; pass novelty to choose rough “energy” area
        jumpToVideoSection(novelty * (0.6 + 0.8 * pScore));

        // Quick white flash
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle = '#fff';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
      }

      // Prepare prevFreq for next frame (copy)
      if (!prevFreq) prevFreq = new Uint8Array(bins);
      prevFreq.set(frequencyData);
    }

    // Update visualizer loop
    function updateVisualizer() {
      // Run new cut logic
      cutLogic();

      // Draw video frame
      if (videoPlaying) {
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
      }

      requestAnimationFrame(updateVisualizer);
    }

    // Load the audio file
    function loadAudioFile(file) {
      audioElement = new Audio();
      audioElement.src = URL.createObjectURL(file);
      audioElement.load();
      audioElement.play();

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;

      const mediaNode = audioContext.createMediaElementSource(audioElement);
      mediaDest = audioContext.createMediaStreamDestination();

      // route: media -> analyser (for visuals), media -> mediaDest (for recording), analyser -> speakers
      mediaNode.connect(analyser);
      mediaNode.connect(mediaDest);
      analyser.connect(audioContext.destination);

      frequencyData = new Uint8Array(analyser.frequencyBinCount);

      // reset onset state for a new run
      prevFreq = null;
      fluxIndex = 0; fluxCount = 0;
      specPtr = 0; specCount = 0;
      onsetTimes.length = 0;
      lastOnsetAt = audioContext.currentTime;
      lastCutTime = audioContext.currentTime;

      // Start the visualization loop
      updateVisualizer();

      // If user enabled recording on splash, start it now that audio graph exists
      if (recordEnabled && !isRecording) {
        beginRecording();
      }
    }

    // Handle audio upload
    audioUpload.addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (file) { audioFile = file; enableStartButton(); }
    });

    // Handle video upload
    videoUpload.addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (file) { videoFile = file; enableStartButton(); }
    });

    // Enable the start button once both files are uploaded
    function enableStartButton() {
      if (audioFile && videoFile) startButton.disabled = false;
    }

    // Hide all UI elements after the start button is clicked
    function hideUI() {
      uploadButtons.style.display = 'none';
      startButton.style.display = 'none';
      canvas.style.display = 'block';
    }

    // Start playback once both files are uploaded
    startButton.addEventListener('click', () => {
      if (audioFile && videoFile) {
        loadAudioFile(audioFile);
        loadVideo(videoFile);
        hideUI();
      }
    });

    // --- Recording logic (WebM via MediaRecorder of canvas + WebAudio) ---
    function beginRecording() {
      if (isRecording) return;
      if (!('MediaRecorder' in window)) {
        alert('Recording not supported in this browser.');
        return;
      }
      const stream = canvas.captureStream(30); // fps
      if (mediaDest && mediaDest.stream && mediaDest.stream.getAudioTracks().length) {
        stream.addTrack(mediaDest.stream.getAudioTracks()[0]);
      }

      const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')
        ? 'video/webm;codecs=vp9,opus'
        : (MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')
            ? 'video/webm;codecs=vp8,opus'
            : 'video/webm');

      mediaRecorder = new MediaRecorder(stream, { mimeType: mime });
      recordedChunks = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) recordedChunks.push(e.data);
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        const ts = new Date().toISOString().replace(/[:.]/g,'-');
        a.download = `music-visualizer-${ts}.webm`;
        document.body.appendChild(a);
        a.click();
        a.remove();
        URL.revokeObjectURL(url);
      };

      mediaRecorder.start();
      isRecording = true;

      // Cursor & UI niceties (cursor not recorded anyway—canvas only—but hide it visually)
      canvas.style.cursor = 'none';
      stopRecordBtn.style.display = 'inline-flex';
    }

    function stopRecording() {
      if (!isRecording) return;
      try { mediaRecorder.stop(); } catch(e) {}
      isRecording = false;
      canvas.style.cursor = '';
      stopRecordBtn.style.display = 'none';
    }

    // Splash toggle for recording
    recordToggleBtn.addEventListener('click', () => {
      recordEnabled = !recordEnabled;
      recordToggleBtn.classList.toggle('active', recordEnabled);
      recordToggleBtn.setAttribute('aria-pressed', String(recordEnabled));
    });

    // Stop button handler
    stopRecordBtn.addEventListener('click', stopRecording);

    // Resize handling
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();
  </script>
</body>
</html>
